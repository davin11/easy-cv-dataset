{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification through fine-tuning\n",
    "In this example, we will perform fine-tuning, which allows you to classify images even when the available dataset is not large enough. The idea is to exploit networks already trained on very large datasets to extract low-level features, and learn only the weights of the layers that are relative to high-level features. It is a very simple form of *transfer learning* which is still very effective.\n",
    "We will apply this strategy to image classification and we will use **keras_hub** and **easy_cv_dataset** libraries that can be installed with the followinh instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19098,
     "status": "ok",
     "timestamp": 1745763533254,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "iHlHyMbIGhRb",
    "outputId": "1a7ac1a6-befe-4c58-93d2-95f341f53231"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade keras_hub git+https://github.com/davin11/easy-cv-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import the stantard libraries, **keras_hub**, and **easy_cv_dataset** (with the alias ds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import keras\n",
    "import keras_hub\n",
    "import easy_cv_dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We will use the dataset TrafficSigns, therefore the objective is to identify whether in the image there is a road sign of the type: mandatory, prohibition or warning. On Notebook you can directly execute the following instructions to download and decompress the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10503,
     "status": "ok",
     "timestamp": 1745763543758,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "7a31vCB_jwGy"
   },
   "outputs": [],
   "source": [
    "!wget -q -c https://www.grip.unina.it/download/guide_TF/TrafficSigns.zip\n",
    "!unzip -q -n TrafficSigns.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find a folder called \"TrafficSigns\" which contains two sub-folders \"train\" and \"test\". Both the \"train\" and \"test\" folders contain the \"mandatory\", \"prohibition\" and \"warning\" folders. Display an image for each traffic signwith the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "executionInfo": {
     "elapsed": 1941,
     "status": "ok",
     "timestamp": 1745763553889,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "JBswxF1gc-eN",
    "outputId": "307a6c55-e2cc-466d-fec0-96f29d67ba34"
   },
   "outputs": [],
   "source": [
    "img0 = io.imread('TrafficSigns/train/mandatory/img0065_00.png')\n",
    "img1 = io.imread('TrafficSigns/train/prohibition/img2929_00.png')\n",
    "img2 = io.imread('TrafficSigns/train/warning/img2470_00.png')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1); plt.imshow(img0); plt.title('mandatory')\n",
    "plt.subplot(1,3,2); plt.imshow(img1); plt.title('prohibition')\n",
    "plt.subplot(1,3,3); plt.imshow(img2); plt.title('warning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOivnpwrc-BH"
   },
   "source": [
    "We proceed to prepare the data using the functions of `ds.image_dataframe_from_directory`,\n",
    "which simplify this operation. Since the images are organized into folders, each of which is associated with a\n",
    "class, we can obtain a list of images with their respective classes by specifying only the parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 8138,
     "status": "ok",
     "timestamp": 1745763562030,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "-n9aU42i5Tbl",
    "outputId": "aa4ded7d-be37-496d-9d75-fde4236bddcf"
   },
   "outputs": [],
   "source": [
    "train_table = ds.image_dataframe_from_directory('TrafficSigns/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous instruction creates a table, called `train_table`, which has two columns: the image column containing the file paths of the training images, and the class column containing the class information for each image. To display the first rows of the table, execute the following instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the training table in two tables for training and validation, respectively using the function `train_test_split` of `sklearn.model_selection`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1745763562272,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "z3qK6X1NINhx",
    "outputId": "bd2f1b3b-57e3-4f14-d527-0798bc48496c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_table, valid_table = train_test_split(train_table, test_size=0.2,\n",
    "                                            random_state=34,\n",
    "                                            stratify=train_table['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to indicate the parameter test size to set the percentage of the validation data to 20%, while the\n",
    "parameter `stratify=train table['class']` is used t o guarantee a balanced division among the classes.\n",
    "By using the function `ds.image_classification_dataset_from_dataframe`, we can prepare the training set\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2886,
     "status": "ok",
     "timestamp": 1745763565157,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "6_YA9fvclj8V",
    "outputId": "0d217952-3cea-4a99-cdd0-afc8a3690f43"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "train_dataset = ds.image_classification_dataset_from_dataframe(\n",
    "  train_table, batch_size=batch_size, shuffle=True,\n",
    "  pre_batching_processing=keras.layers.Resizing(img_height, img_width),\n",
    "  post_batching_processing=None,\n",
    "  do_normalization=False,\n",
    "  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `ds.image_classification_dataset_from_dataframe` requires the previously created table as its first parameter.\n",
    "The second parameter, `batch_size`, indicates the size of the batch that will be used during training and has to be specified to determine how many images should be processed together.\n",
    "The `shuffle` parameter indicates whether the dataset should be shuffled at the beginning of each epoch.\n",
    "The `pre_batching_processing` and `post_batching_processing` parameters allow for applying an operation to all images in the dataset before and after the batch construction, respectively. When dealing with images of different resolutions, we can specify a resizing operation before batching to resize the images to a given dimension.\n",
    "The parameter `do_normalization` can be used to normalize the images to range [0, 1].\n",
    "It is set `False` because the normalizztion is made by the model in this examples.\n",
    "The last parameter, `class_mode`, is used to indicate the format of the labels. By using the string `'categorical'` the OneHot format will be utilized.\n",
    "Let's also prepare the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = ds.image_classification_dataset_from_dataframe(\n",
    "  valid_table, batch_size=batch_size, shuffle=False,\n",
    "  pre_batching_processing=keras.layers.Resizing(img_height, img_width),\n",
    "  do_normalization=False,\n",
    "  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition\n",
    "Fine-tuning consists in training a network not starting from random weights,\n",
    "but using the weights already obtained from a pre-training on another dataset (much larger than the one available). In particular, we use the weights relative to the first layers that extract features common to many images (low-level features) and retrain subsequent layers, that extract specific features of the specific application.\n",
    "Let's define ResNet50 backbone pre-trained on ImageNet using **keras_hub** library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2575,
     "status": "ok",
     "timestamp": 1745763567949,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "rLqYHcaRhfUE",
    "outputId": "2ba66e19-fff9-4ce4-a6a7-d90847efc9dd"
   },
   "outputs": [],
   "source": [
    "from keras_hub.models import Backbone\n",
    "\n",
    "pretrained_model = 'resnet_50_imagenet'\n",
    "backbone = Backbone.from_preset(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Backbone** is the network architecure without the last head block.\n",
    "The function `Backbone.from_preset` creates the architecture and loads the weights specifying the pretrained model.\n",
    "A list of available pretrained models is at the web page https://keras.io/keras_hub/presets/\n",
    "\n",
    "During pre training, each model use a specific image preparation, we need to create a layer that makes the same preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_hub.layers import ImageConverter\n",
    "normalization = ImageConverter.from_preset(pretrained_model, image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a model for image classification that includes the backbone and subsequently performs a GlobalAveragePooling and a Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1745763567989,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "EsEMAPd0iX53",
    "outputId": "fc07001f-ccf6-4081-9c95-d4f8915c672b"
   },
   "outputs": [],
   "source": [
    "from keras_hub.models import ImageClassifier, ImageClassifierPreprocessor\n",
    "model = ImageClassifier(\n",
    "    preprocessor=ImageClassifierPreprocessor(normalization),\n",
    "    backbone=backbone,\n",
    "    pooling=\"avg\",          # GlobalAveragePooling layer\n",
    "    num_classes=3,          # units of Dense layer\n",
    "    activation=\"softmax\",   # activation function of Dense layer\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not training the first layers reduces the parameters to be learned and also the risk of over-fitting. To lock the parameters of the first 25 layers of ResNet50 use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1745763568009,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "rfh9jhhPjRS1",
    "outputId": "e4909421-6e36-40f8-ef49-083aa6802cc2"
   },
   "outputs": [],
   "source": [
    "train_after_layer = 25\n",
    "for layer in model.backbone.layers[:train_after_layer]:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We define the optimizer and the loss function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745763568024,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "IC0TKmm0j68e"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "             optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
    "             metrics=[keras.metrics.CategoricalAccuracy(), ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a very low learning rate since we do not start from random weights. We need to use the fit method for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194022,
     "status": "ok",
     "timestamp": 1745763762048,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "1QY-T54jkNqf",
    "outputId": "8bf1c5d1-8cef-4959-b3af-88932d321c78"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset,  validation_data=valid_dataset, epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with only five epoch we are able to obtain an accuracy on validation data greater than 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Use the functions `ds.image_dataframe_from_directory` and `ds.image_classification_dataset_from_dataframe` to prepare the images for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1745763762186,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "QmmKQmizmK9-",
    "outputId": "6cf5337e-b4d7-4e2b-eeb0-2d1157e74a5c"
   },
   "outputs": [],
   "source": [
    "test_table = ds.image_dataframe_from_directory('TrafficSigns/test')\n",
    "test_dataset = ds.image_classification_dataset_from_dataframe(\n",
    "    test_table, batch_size=batch_size, shuffle=False,\n",
    "    pre_batching_processing=keras.layers.Resizing(img_height, img_width),\n",
    "    do_normalization=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance on the test set then run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1751,
     "status": "ok",
     "timestamp": 1745763763938,
     "user": {
      "displayName": "davide cozzolino",
      "userId": "01048783342148768927"
     },
     "user_tz": -120
    },
    "id": "EUWJQtEAmXmS",
    "outputId": "755859b8-6376-4795-d752-c20c4966101d"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=True)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "We can apply various random operations to the training images, allowing us to artificially increase the size of the training dataset through data augmentation. For this purpose, we can utilize the random operations defined in the `keras.layers` preprocessing library. Additionally, we can combine these operations together using `keras.layers.Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RandomBrightness, RandomZoom, Pipeline\n",
    "augmenter = Pipeline(layers=[\n",
    "  RandomBrightness(factor=(-0.1, 0.1), value_range=(0, 255)),\n",
    "  RandomZoom((-0.2,0.2)),\n",
    "])\n",
    "\n",
    "train_dataset = ds.image_classification_dataset_from_dataframe(\n",
    "          train_table, batch_size=batch_size, shuffle=True,\n",
    "          pre_batching_processing=keras.layers.Resizing(img_height, img_width),\n",
    "          post_batching_processing=augmenter,\n",
    "          do_normalization=False,\n",
    "          class_mode='categorical')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO19ktpJNYfRwsRxCucLdxE",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf2.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
